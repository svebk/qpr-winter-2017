{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data\n",
    "The goal of this notebook is to train and evaluated HT risk classification using statistics from the images and the faces detect in the images associated to the set of ads provided for the CP1 during the MEMEX Winter QPR 2017.\n",
    "[Most of the code from Mayank repo]\n",
    "\n",
    "### Input files\n",
    "1. clusters images based features for training and testing\n",
    "\n",
    "### Outputs\n",
    "1. eval file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_string_to_float_list(string):\n",
    "    return [float(i) for i in re.split(', ', string[1:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_norm_on_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Takes a np.matrix style object and l2-normalizes it.\n",
    "    :param matrix:\n",
    "    :return matrix:\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import normalize\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    return normalize(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_and_extend(list_of_vectors, total_samples):\n",
    "    \"\"\"\n",
    "    Oversampling code for balanced training. We will do deep re-sampling, assuming that the vectors contain\n",
    "    atoms.\n",
    "    :param list_of_vectors: the list of vectors that are going to be re-sampled (randomly)\n",
    "    :param total_samples: The total number of vectors that we want in the list. Make sure that this number\n",
    "    is higher than the length of list_of_vectors\n",
    "    :return: the over-sampled list\n",
    "    \"\"\"\n",
    "    if len(list_of_vectors) >= total_samples:\n",
    "        raise Exception('Check your lengths!')\n",
    "\n",
    "    indices = range(0, len(list_of_vectors))\n",
    "    shuffle(indices)\n",
    "    desired_samples = total_samples-len(list_of_vectors)\n",
    "    # print desired_samples>len(list_of_vectors)\n",
    "    while desired_samples > len(indices):\n",
    "        new_indices = list(indices)\n",
    "        shuffle(new_indices)\n",
    "        indices += new_indices\n",
    "    new_data = [list(list_of_vectors[i]) for i in indices[0:desired_samples]]\n",
    "    # print new_data\n",
    "    return np.append(list_of_vectors, new_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_ML_classification(pos_neg_file, normalize=False):\n",
    "    \"\"\"\n",
    "    We need to read in embeddings\n",
    "    :param pos_neg_file: The file generated in one of the preprocess_filtered_* files\n",
    "    :return: A dictionary where a 0,1 label references a numpy matrix.\n",
    "    \"\"\"\n",
    "    result = dict()\n",
    "    pos_features = list()\n",
    "    neg_features = list()\n",
    "    with codecs.open(pos_neg_file, 'r', 'utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line[0:-1]\n",
    "            cols = re.split('\\t',line)\n",
    "            # print list(cols[1])\n",
    "            # break\n",
    "            if int(cols[2]) == 1:\n",
    "                pos_features.append(convert_string_to_float_list(cols[1]))\n",
    "            elif int(cols[2]) == 0:\n",
    "                neg_features.append(convert_string_to_float_list(cols[1]))\n",
    "            else:\n",
    "                print 'error; label not recognized'\n",
    "    # print np.matrix(pos_features)\n",
    "    if normalize == True:\n",
    "        result[0] = l2_norm_on_matrix(np.matrix(neg_features))\n",
    "        result[1] = l2_norm_on_matrix(np.matrix(pos_features))\n",
    "    else:\n",
    "        if len(pos_features) != 0:\n",
    "            result[1] = pos_features\n",
    "        if len(neg_features) != 0:\n",
    "            result[0] = neg_features\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_test_data(pos_neg_file, train_percent = 0.3, randomize=True, balanced_training=True, data_vectors=None):\n",
    "    \"\"\"\n",
    "    :param pos_neg_file:\n",
    "    :param train_percent:\n",
    "    :param randomize: If true, we'll randomize the data we're reading in from pos_neg_file. Otherwise, the initial\n",
    "    train_percent fraction goes into the training data and the rest of it in the test data\n",
    "    :param balanced_training: if True, we will equalize positive and negative training samples by oversampling\n",
    "    the lesser class. For example, if we have 4 positive samples and 7 negative samples, we will randomly re-sample\n",
    "    3 positive samples from the 4 positive samples, meaning there will be repetition. Use with caution.\n",
    "    :param data_vectors: this should be set if pos_neg_file is None. It is mostly for internal uses, so\n",
    "    that we can re-use this function by invoking it from some of the other _prepare_ files.\n",
    "    :return: dictionary containing training/testing data/labels\n",
    "    \"\"\"\n",
    "    import math\n",
    "    if pos_neg_file:\n",
    "        data = prepare_for_ML_classification(pos_neg_file)\n",
    "    elif data_vectors:\n",
    "        data = data_vectors\n",
    "    else:\n",
    "        raise Exception('Neither pos_neg_file nor data_vectors argument is specified. Exiting.')\n",
    "\n",
    "    # print len(data[1])\n",
    "    # print len(data[0])\n",
    "    train_pos_num = int(math.ceil(len(data[1])*train_percent))\n",
    "    train_neg_num = int(math.ceil(len(data[0])*train_percent))\n",
    "    # print train_pos_num\n",
    "    # print train_neg_num\n",
    "    test_pos_num = len(data[1])-train_pos_num\n",
    "    test_neg_num = len(data[0])-train_neg_num\n",
    "    if test_pos_num == 0:\n",
    "        test_pos_num = 1\n",
    "    if test_neg_num == 0:\n",
    "        test_neg_num = 1\n",
    "\n",
    "    test_labels_pos = [[1] * test_pos_num]\n",
    "    test_labels_neg = [[0] * test_neg_num]\n",
    "\n",
    "    if not randomize:\n",
    "        train_data_pos = data[1][0:train_pos_num]\n",
    "        train_data_neg = data[0][0:train_neg_num]\n",
    "        if train_pos_num < len(data[1]):\n",
    "            test_data_pos = data[1][train_pos_num:]\n",
    "        else:\n",
    "            test_data_pos = [data[1][-1]]\n",
    "\n",
    "        if train_neg_num < len(data[0]):\n",
    "            test_data_neg = data[0][train_neg_num:]\n",
    "        else:\n",
    "            test_data_neg = [data[0][-1]]\n",
    "\n",
    "    else:\n",
    "        all_pos_indices = range(0, len(data[1]))\n",
    "        all_neg_indices = range(0, len(data[0]))\n",
    "        shuffle(all_pos_indices)\n",
    "        shuffle(all_neg_indices)\n",
    "\n",
    "        train_data_pos = [data[1][i] for i in all_pos_indices[0:train_pos_num]]\n",
    "        train_data_neg = [data[0][i] for i in all_neg_indices[0:train_neg_num]]\n",
    "\n",
    "        if train_pos_num < len(data[1]):\n",
    "            test_data_pos = [data[1][i] for i in all_pos_indices[train_pos_num:]]\n",
    "        else:\n",
    "            test_data_pos = [data[1][-1]]\n",
    "\n",
    "        if train_neg_num < len(data[0]):\n",
    "            test_data_neg = [data[0][i] for i in all_neg_indices[train_neg_num:]]\n",
    "        else:\n",
    "            test_data_neg = [data[0][-1]]\n",
    "\n",
    "    if balanced_training:\n",
    "        if train_pos_num < train_neg_num:\n",
    "            train_labels_pos = [[1] * train_neg_num]\n",
    "            train_labels_neg = [[0] * train_neg_num]\n",
    "            train_data_pos = sample_and_extend(train_data_pos, total_samples=train_neg_num)\n",
    "        elif train_pos_num > train_neg_num:\n",
    "            train_labels_pos = [[1] * train_pos_num]\n",
    "            train_labels_neg = [[0] * train_pos_num]\n",
    "            train_data_neg = sample_and_extend(train_data_neg, total_samples=train_pos_num)\n",
    "        else:\n",
    "            train_labels_pos = [[1] * train_pos_num]\n",
    "            train_labels_neg = [[0] * train_neg_num]\n",
    "    else:\n",
    "        train_labels_pos = [[1] * train_pos_num]\n",
    "        train_labels_neg = [[0] * train_neg_num]\n",
    "\n",
    "    # print len(train_data_pos)\n",
    "    # print len(train_data_neg)\n",
    "    train_data = np.append(train_data_pos, train_data_neg, axis=0)\n",
    "    test_data = np.append(test_data_pos, test_data_neg, axis=0)\n",
    "    train_labels = np.append(train_labels_pos, train_labels_neg)\n",
    "    test_labels = np.append(test_labels_pos, test_labels_neg)\n",
    "\n",
    "    results = dict()\n",
    "    results['train_data'] = train_data\n",
    "    results['train_labels'] = train_labels\n",
    "    results['test_data'] = test_data\n",
    "    results['test_labels'] = test_labels\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_classifier(train_data, train_labels, test_data, test_labels, classifier_model, test_ids=None):\n",
    "        \"\"\"\n",
    "        Take three numpy matrices and compute a bunch of metrics. Hyperparameters must be changed manually,\n",
    "        we do not take them in as input.\n",
    "        This method is for BINARY CLASSIFICATION only, although there is some support for regression.\n",
    "        :param train_data:\n",
    "        :param train_labels:\n",
    "        :param test_data:\n",
    "        :param test_labels:\n",
    "        :param classifier_model:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, precision_recall_fscore_support\n",
    "        if classifier_model == 'random_forest':\n",
    "            model = RandomForestClassifier()\n",
    "            model.fit(train_data, train_labels)\n",
    "            # joblib.dump(model, '/Users/mayankkejriwal/git-projects/dig-random-indexing-extractor/test/model')\n",
    "            predicted_labels = model.predict(test_data)\n",
    "            print predicted_labels\n",
    "            predicted_probabilities = model.predict_proba(test_data)\n",
    "            print predicted_probabilities\n",
    "            # print predicted_labels[0:10]\n",
    "            # print predicted_probabilities[0:10]\n",
    "        elif classifier_model == 'knn':\n",
    "            k = 9\n",
    "            model = neighbors.KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "            model.fit(train_data, train_labels)\n",
    "            predicted_labels = model.predict(test_data)\n",
    "            predicted_probabilities = model.predict_proba(test_data)\n",
    "            print predicted_probabilities\n",
    "        elif classifier_model == 'logistic_regression':\n",
    "            model = LogisticRegression()\n",
    "            model.fit(train_data, train_labels)\n",
    "            predicted_labels = model.predict(test_data)\n",
    "            predicted_probabilities = model.predict_proba(test_data)\n",
    "        elif classifier_model == 'linear_regression': # this is a regressor; be careful.\n",
    "            model = LinearRegression()\n",
    "            model.fit(train_data, train_labels)\n",
    "            predicted_labels = model.predict(test_data)\n",
    "\n",
    "        final_results = list()\n",
    "        if test_ids is not None:\n",
    "            final_results.append(test_ids)\n",
    "            final_results.append(predicted_probabilities)\n",
    "            return final_results\n",
    "        else:\n",
    "            print 'AUC (Area Under Curve): ',\n",
    "            print roc_auc_score(test_labels, predicted_labels)\n",
    "\n",
    "        # precision, recall, thresholds = precision_recall_curve(test_labels, predicted_labels)\n",
    "        # plt.clf()\n",
    "        # plt.plot(recall, precision, label='precision-recall-curve')\n",
    "        # plt.xlabel('Recall')\n",
    "        # plt.ylabel('Precision')\n",
    "        # plt.ylim([0.0, 1.05])\n",
    "        # plt.xlim([0.0, 1.0])\n",
    "        # plt.title('Precision-Recall curve')\n",
    "        # plt.savefig('/home/mayankkejriwal/Downloads/memex-cp4-october/tmp/fig.png')\n",
    "        if classifier_model not in ['linear_regression']:\n",
    "            print 'Accuracy: ',\n",
    "            print accuracy_score(test_labels, predicted_labels)\n",
    "            # print precision_score(test_labels, predicted_labels)\n",
    "            prf = ['Precision: ', 'Recall: ', 'F-score: ', 'Support: ']\n",
    "            print 'Class 0\\tClass 1'\n",
    "            k = precision_recall_fscore_support(test_labels, predicted_labels)\n",
    "            for i in range(0, len(k)):\n",
    "                print prf[i],\n",
    "                print k[i]\n",
    "            return [k[0][1], k[1][1], k[2][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "data_dir = \"../data\"\n",
    "prefix = \"train\"\n",
    "#prefix = \"test\"\n",
    "if prefix==\"train\":\n",
    "    input_file = \"train_adjusted.json\"\n",
    "else:\n",
    "    input_file = \"test_adjusted_unlabelled.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/isolve/_iterative.so, 2): Library not loaded: libmkl_intel_lp64.dylib\n  Referenced from: /Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/isolve/_iterative.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-192a609e8130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 'logistic_regression', 'random_forest', 'knn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier_model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'logistic_regression'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_test_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c4e19a01e8b6>\u001b[0m in \u001b[0;36mtrain_and_test_classifier\u001b[0;34m(train_data, train_labels, test_data, test_labels, classifier_model, test_ids)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random_forest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[0;31m# avoid flakes unused variable error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChangedBehaviorWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_ChangedBehaviorWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from .validation import (as_float_array,\n\u001b[0m\u001b[1;32m     12\u001b[0m                          \u001b[0massert_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_DataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_scipy_sparse_lsqr_backport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0misolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdsolve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/isolve/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#from info import __doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0miterative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mminres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlgmres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlgmres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/isolve/iterative.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bicg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bicgstab'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cgs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gmres'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'qmr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_iterative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/isolve/_iterative.so, 2): Library not loaded: libmkl_intel_lp64.dylib\n  Referenced from: /Users/svebor/anaconda/lib/python2.7/site-packages/scipy-0.18.1-py2.7-macosx-10.6-x86_64.egg/scipy/sparse/linalg/isolve/_iterative.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "train_percent = 0.5\n",
    "pos_neg_file = os.path.join(data_dir, prefix+\"_images_faces_stats_mayank.tsv\")\n",
    "data_dict = prepare_train_test_data(pos_neg_file, train_percent=train_percent)\n",
    "# 'logistic_regression', 'random_forest', 'knn'\n",
    "data_dict['classifier_model'] = 'logistic_regression'\n",
    "results = train_and_test_classifier(**data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
